---
layout: post
title:  "Iterative Closest Point"
date:   2018-09-30 15:00:00 -0200
description: ICP.
permalink: /ICP/
---

### Usage:

  In SLAM systems, the ICP algorithm is usually used in the front-end, i.e. visual odometry, for 3D-3D pose estimation.

### Problem Setup:

  Given 2 sets of matched 3D points (assuming that we already matched 2 RGB-D images, details refering to the problem known as *data association / point matching / correspondence finding*):

  $$ \boldsymbol{P} = \{\boldsymbol{p}_1, \boldsymbol{p}_2, \dots, \boldsymbol{p}_n\} $$

  $$ \boldsymbol{P}' = \{\boldsymbol{p}'_1, \boldsymbol{p}'_2, \dots, \boldsymbol{p}'_n\} $$

  We would like to find a transformation $$\boldsymbol{R}$$, $$\boldsymbol{t}$$, such that 

  $$ \forall i, \boldsymbol{p}_i = \boldsymbol{R}\boldsymbol{p}'_i + \boldsymbol{t} $$

  ps. inhomogeneous coordinates are used here and below.

### Solutions:

  Before diving into the solutions, we should notice that camera model (intrinsic and extrinsic parameters of the camera) is not quite relevant when trying to find the transformation between 2 sets of 3D points. 

  In order to find the desired transformation, we first formulate this problem in the least square manner:

  $$ \boldsymbol{R}^*, \boldsymbol{t}^* = \underset{ \boldsymbol{R}, \boldsymbol{t} } {\mathrm{argmin}} \frac{1}{2} \sum_{i=1}^n \parallel \boldsymbol{p}_i - (\boldsymbol{R}\boldsymbol{p}'_i + \boldsymbol{t})  \parallel^2 $$

  Like any other least square problems, there are 2 methods of finding the optimal transformation: Linear Estimation and Non-Linear Optimization.

  - Linear Estimation

    The most popular linear estimation method is Singular Value Decomposition (SVD), which is discussed thoroughly in <u>Appendix 1</u>. Here we focus on how SVD can be used to solve the optimal transformation.

    - Reduce the number of parameters

      Optimizing over 2 parameters is more difficult than optimizing over only 1 parameter. Therefore, we first reduce the number parameters in this least square problem.

      By defining the centroids of each set of the points:

      $$ \boldsymbol{p} = \frac{1}{2} \sum_{i=1}^n \boldsymbol{p_i}, \quad \boldsymbol{p}' = \frac{1}{2} \sum_{i=1}^n \boldsymbol{p_i}' $$

      the least square term can now be expressed as below with mathematical details in <u>Appendix 2</u>:
    
      $$ \sum_{i=1}^n \parallel \boldsymbol{p_i} - (\boldsymbol{R}\boldsymbol{p_i}' + \boldsymbol{t}) \parallel^2 = \sum_{i=1}^n \parallel \boldsymbol{p_i} - \boldsymbol{p} - \boldsymbol{R}(\boldsymbol{p_i}' - \boldsymbol{p}') \parallel^2 + \parallel \boldsymbol{p} - \boldsymbol{R}\boldsymbol{p}' - \boldsymbol{t} \parallel^2 $$ 

      let $$ \boldsymbol{q_i} = \boldsymbol{p_i} - \boldsymbol{p}$$, $$ \boldsymbol{q_i}' = \boldsymbol{p_i}' - \boldsymbol{p}' $$, we have

      $$ \underset{ \boldsymbol{R}, \boldsymbol{t} }{\mathrm{argmin}} \frac{1}{2} \sum_{i=1}^n \parallel \boldsymbol{p_i} - (\boldsymbol{R}\boldsymbol{p_i}' + \boldsymbol{t}) \parallel^2 = \underset{ \boldsymbol{R}, \boldsymbol{t} }{\mathrm{argmin}} \frac{1}{2} \sum_{i=1}^n \parallel \boldsymbol{q_i} - \boldsymbol{R}\boldsymbol{q_i}' \parallel^2 + \parallel \boldsymbol{p} - \boldsymbol{R}\boldsymbol{p}' - \boldsymbol{t} \parallel^2 $$

      Noticing that the first term of the R.H.S. is irrelavent of 
      $$ \boldsymbol{t} $$
      , so we can find the 
      $$ \boldsymbol{R}^* $$ 
      by 

      | $$ \boldsymbol{R}^* = \underset{ \boldsymbol{R} }{\mathrm{argmin}} \frac{1}{2} \sum_{i=1}^n \parallel \boldsymbol{q_i} - \boldsymbol{R}\boldsymbol{q_i}' \parallel ^2$$ |
      
      and then calculate 
      $$ \boldsymbol{t}^* $$ 
      by setting the second term to be zero, i.e. 
      
      | $$ \boldsymbol{t}^* = \boldsymbol{p} - \boldsymbol{R}^* \boldsymbol{p}' $$ |

    - Find $$ \boldsymbol{R}^* $$

      Expanding equation $$ \frac{1}{2} \sum_{i=1}^n \parallel \boldsymbol{q_i} - \boldsymbol{R}\boldsymbol{q_i}' \parallel ^2 $$ we have

      $$ \frac{1}{2} \sum_{i=1}^n \boldsymbol{q_i}^T \boldsymbol{q_i} + \boldsymbol{q_i}'^T \boldsymbol{R}^T \boldsymbol{R} \boldsymbol{q_i}' - 2 \boldsymbol{q_i}^T \boldsymbol{R} \boldsymbol{q_i}' $$

      Due to the orthogonality of the rotation matrix, i.e. $$ \boldsymbol{R}^T \boldsymbol{R} = \boldsymbol{I} $$, both the first 2 terms are irrelavant to $$ \boldsymbol{R} $$. Hence the least square problem becomes:

      $$ \boldsymbol{R}^* = \underset{ \boldsymbol{R} }{\mathrm{argmax}} \frac{1}{2} \sum_{i=1}^n \boldsymbol{q_i}^T \boldsymbol{R} \boldsymbol{q_i}' $$

      now we try to isolate $$\boldsymbol{R}$$ out of the summation (mathematical details can be found in <u>Appendix 3</u>:

      $$ \sum_{i=1}^n \boldsymbol{q_i}^T \boldsymbol{R} \boldsymbol{q_i}' = tr(\boldsymbol{R} \sum_{i=1}^n \boldsymbol{q_i}' \boldsymbol{q_i}^T) $$

      By defining matrix $$ \boldsymbol{H} = \sum_{i=1}^n \boldsymbol{q_i}' \boldsymbol{q_i}^T $$, we can find the optimal rotation matrix by performing SVD on $$ \boldsymbol{H} $$:

      $$ \boldsymbol{H} = \boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^T $$

      where $$ \boldsymbol{\Sigma} $$ is a diagonal matrix with nonnegative sigular values in descending order, and $$ \boldsymbol{U} $$ and $$ \boldsymbol{V} $$ are both orthonormal matrices. When matrix $$ det(\boldsymbol{H}) = 1 $$, we have,

      | $$ \boldsymbol{R}^* = \boldsymbol{V}\boldsymbol{U}^T $$ |

      Mathematical details about the optimality can be found in <u>Appendix 4</u>.

  - Non-Linear Optimization

    Non-Linear optimization method can solve for the optimal transformation in an interative manner.

    Details To Be Added...


### Variants:
  
  More about efficient variants of ICP algorithms will be discussed along with how they are used in SLAM++. 


### Reference:

[1] 高翔；张涛；刘毅；严沁睿: "视觉SLAM十四讲，从理论到实践".

[2] F. Pomerleau, F. Colas, R. Siegwart. "A Review of Point Cloud Registration Algorithms for Mobile Robotics". Foundations and Trends in Robotics. 4 (1): 1–104, 2015.

[3] K. S. Arun, T. S. Huang, and S. D. Blostein. Least-Squares Fitting of Two 3-D Point Sets. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 9(5):698–700, 1987.

[n] S. Rusinkiewicz, M. Levoy. "Efficient Variants of the ICP Algorithm". In Proceedings of the IEEE International Workshop on 3D Digital Imaging and Modeling (3DIM), 2001.


### Appendix
  1.

  2.

  $$
  \begin{split}
    \sum_{i=1}^n \parallel \boldsymbol{p_i} - (\boldsymbol{R}\boldsymbol{p_i}' + \boldsymbol{t}) \parallel^2 
    &= \sum_{i=1}^n \parallel (\boldsymbol{p_i} - \boldsymbol{p}) + \boldsymbol{p} - \boldsymbol{R} ( \boldsymbol{p_i}' - \boldsymbol{p}' ) - \boldsymbol{R}\boldsymbol{p}' -\boldsymbol{t} \parallel^2 \\
    &= \sum_{i=1}^n \parallel (\boldsymbol{p_i} - \boldsymbol{p}  - \boldsymbol{R} ( \boldsymbol{p_i}' - \boldsymbol{p}' ) ) + (\boldsymbol{p} - \boldsymbol{R}\boldsymbol{p}' -\boldsymbol{t}) \parallel^2 \\
    &= \sum_{i=1}^n \parallel \boldsymbol{p_i} - \boldsymbol{p}  - \boldsymbol{R} ( \boldsymbol{p_i}' - \boldsymbol{p}' ) \parallel^2 + \sum_{i=1}^n \parallel \boldsymbol{p} - \boldsymbol{R}\boldsymbol{p}' -\boldsymbol{t} \parallel^2 - 2 \sum_{i=1}^n (\boldsymbol{p_i} - \boldsymbol{p}  - \boldsymbol{R} ( \boldsymbol{p_i}' - \boldsymbol{p}' ))^T (\boldsymbol{p} - \boldsymbol{R}\boldsymbol{p}' -\boldsymbol{t})
  \end{split}
  $$

  By the definition of the centroids, we can find that $$ \sum_{i=1}^n \boldsymbol{p_i} - \boldsymbol{p}  - \boldsymbol{R} ( \boldsymbol{p_i}' - \boldsymbol{p}' ) = 0 $$. Therefore, we have: 

  $$ \sum_{i=1}^n \parallel \boldsymbol{p_i} - (\boldsymbol{R}\boldsymbol{p_i}' + \boldsymbol{t}) \parallel^2 = \sum_{i=1}^n \parallel \boldsymbol{p_i} - \boldsymbol{p} - \boldsymbol{R}(\boldsymbol{p_i}' - \boldsymbol{p}') \parallel^2 + \parallel \boldsymbol{p} - \boldsymbol{R}\boldsymbol{p}' - \boldsymbol{t} \parallel^2 $$ 

  3.

  Assume that $$ \boldsymbol{v_i} = \boldsymbol{R}\boldsymbol{q_i}' $$, we have

  $$ \sum_{i=1}^n \boldsymbol{q_i}^T \boldsymbol{R} \boldsymbol{q_i}' = \sum_{i=1}^n \boldsymbol{q_i}^T \boldsymbol{v_i} $$

  Additionally, assume that $$ \boldsymbol{q_i} = (x_i, y_i, z_i)^T $$, $$ \boldsymbol{v_i} = (a_i, b_i, c_i)^T $$, we have

  $$ 
  \begin{split}
    \sum_{i=1}^n \boldsymbol{q_i}^T \boldsymbol{v_i} 
    &= \sum_{i=1}^n (x_i, y_i, z_i)(a_i, b_i, c_i)^T \\
    &= \sum_{i=1}^n x_ia_i + y_ib_i + z_ic_i \\
    &= \sum_{i=1}^n tr(
    \begin{pmatrix}
      x_ia_i & \dots & \dots \\
      \dots & y_ib_i & \dots \\
      \dots & \dots & z_ic_i
    \end{pmatrix}
    ) \\
    &= \sum_{i=1}^n tr(\boldsymbol{v_i} \boldsymbol{q_i}^T) \\
    &= tr(\sum_{i=1}^n \boldsymbol{v_i} \boldsymbol{q_i}^T ) \\
    &= tr(\sum_{i=1}^n \boldsymbol{R} \boldsymbol{q_i}' \boldsymbol{q_i}^T) \\
    &= tr(\boldsymbol{R} \sum_{i=1}^n \boldsymbol{q_i}' \boldsymbol{q_i}^T) 
  \end{split}
  $$

  4.

  Quote from [3]:
  > <u>Lemma</u>: For any positive definite matrix $$\boldsymbol{A}$$, and any orthonomal matrix $$\boldsymbol{B}$$,

  > $$ tr(\boldsymbol{A}) \geq tr(\boldsymbol{B}\boldsymbol{A}) $$
  
  > <u>Proof of Lemma refer to [3]</u>.
  
  > Let the SVD of H be $$ \boldsymbol{H} = \boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^T $$,

  > and $$ \boldsymbol{X} = \boldsymbol{V}\boldsymbol{U}^T $$.

  > So, we have

  > $$ \boldsymbol{X}\boldsymbol{H} = \boldsymbol{V} \boldsymbol{U}^T boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^T = \boldsymbol{V} \boldsymbol{\Sigma} \boldsymbol{V}^T$$

  > which is symmetrical and positive definite. Using the Lemma above, for any orthonormal matrix $$ \boldsymbol{B} $$,

  > $$ tr(\boldsymbol{X}\boldsymbol{H}) \geq tr(\boldsymbol{B}\boldsymbol{X}\boldsymbol{H}) $$

  > i.e. among all 3x3 orthonomal matrices, $$ \boldsymbol{X} $$ maximizes $$ tr(\boldsymbol{R} \sum_{i=1}^n \boldsymbol{q_i}' \boldsymbol{q_i}^T) = \sum_{i=1}^n \boldsymbol{q_i}^T \boldsymbol{R} \boldsymbol{q_i}' $$。

  > By definition, rotation matrices are special orthogonal matrices, thus $$ det(\boldsymbol{X}) = 1 $$. It is a reflection matrix if $$ det(\boldsymbol{X}) = -1 $$.



